# Обработка сканов паспортов

**Это консольное приложение, которое автоматически распознаёт и размечает персональные данные, находящиеся на третьей странице скана паспорта.**

Программа предназначена для работы с уже обрезанными и ровными по тону сканами. 

## Обоснование выбора методов и исследование подходов

Задача заключалась в разработке консольного приложения, которое автоматически распознаёт и размечает персональные данные, находящиеся на третьей странице скана паспорта. В ходе работы я провёл исследование различных подходов к обработке и распознаванию текстовой информации на сканах документов.

В качестве основного решения я выбрал классические методы компьютерного зрения, поскольку проект ориентирован на работу с уже обрезанными и ровными по тону сканами паспортов. Такой подход позволяет добиться высокой скорости обработки и стабильных результатов без необходимости использования тяжёлых нейросетевых моделей.

Обработка начинается с выравнивания размеров изображений, что обеспечивает единообразие входных данных. Далее применяется гамма-коррекция и CLAHE (адаптивное гистограммное выравнивание), что позволяет улучшить контраст и повысить качество распознавания текста. Размытие по Гауссу помогает снизить уровень шума, а бинаризация методом Отцу позволяет чётко отделить текст от фона.

Для выделения текстовых областей я использую морфологические операции — закрытие и открытие. Эти методы позволяют эффективно объединять разрозненные элементы текста и удалять мелкие шумы. После морфологической обработки происходит фильтрация лишних контуров, что позволяет выделить только значимые области с текстом. Для каждой такой области строится отдельная рамка. Для распознавания текста в выделенных областях применяется OCR-движок Tesseract.

Стоит отметить, что распознавание не идеально и требует тонкой настройки параметров для достижения наилучших результатов. В процессе работы могут возникать артефакты на итоговом размеченном изображении, поэтому важно внедрять дополнительные средства фильтрации и постобработки. В качестве экспериментов по улучшению выделения областей я бы пробовал применять адаптивную бинаризацию и билатеральный фильтр, что в ряде случаев должно позволить повысить качество сегментации текста.

В ходе исследования я также рассматривал современные нейросетевые методы, такие как CRAFT (Character Region Awareness for Text Detection), которые показывают отличные результаты на сложных и неструктурированных изображениях. Однако для данной задачи классические морфологические методы оказались более эффективными и быстрыми, учитывая специфику входных данных.

В качестве метрик качества, помимо IoU и Character Accuracy, также можно использовать CRR (Character Recognition Rate) и WRR (Word Recognition Rate) для более комплексной оценки результатов распознавания.

## Установка

1. Клонируйте репозиторий:
```bash
git clone <repository-url>
cd <repository-name>
```

2. Установите зависимости:
```bash
pip install -r requirements.txt
```

3. Установите Tesseract OCR 

## Использование

### Обработка одного изображения

```bash
# Обработка одного изображения
python main.py --input path/to/image.jpg --output path/to/output/dir

# Обработка директории с изображениями
python main.py --input path/to/input/dir --output path/to/output/dir

# Использование значений по умолчанию (img/ -> output/)
python main.py
```

### Параметры командной строки

- `--input` или `-i`: путь к входному файлу или директории (по умолчанию: `img`)
- `--output` или `-o`: путь к выходной директории (по умолчанию: `output`)
- `--config` или `-c`: путь к файлу конфигурации (опционально)

Все входные изображения должны быть только в формате JPG или PNG.

## Структура проекта

- `image_processor.py` - основной класс для обработки изображений
- `contour_processor.py` - класс для обработки контуров и распознавания полей
- `metrics.py` - функции для расчета метрик качества распознавания
- `utils.py` - вспомогательные функции
- `config.py` - конфигурационные параметры
- `main.py` - точка входа в программу
- `requirements.txt` - зависимости проекта

## Формат выходных данных

Результаты сохраняются в двух форматах:

1. Изображение с отрисованными контурами (`*_contours.jpg`)
2. JSON файл с распознанными данными (`*_passport.json`)

Пример JSON:
```json
{
  "image_info": {
    "width": 800,
    "height": 1200
  },
  "fields": [
    {
      "type": "surname",
      "value": "Иванов",
      "bbox": [x, y, width, height]
    },
    // ... другие поля
  ]
}
```

## Пример результата распознавания

Ниже приведён пример изображения с отрисованными рамками вокруг распознанных полей паспорта:

![Пример распознавания рамок](./@Снимок%20экрана%202025-04-27%20в%2019.39.40_ground_truth.jpg)

На изображении цветными рамками выделены:
- **photo** — фотография (синяя рамка)
- **surname, name, patronymic, birth_date, gender, birth_place** — текстовые поля (зелёные рамки)
- **passport_number** — серия и номер паспорта (красная рамка)

## Метрики качества

Проект использует две основные метрики для оценки качества распознавания:

1. **IoU (Intersection over Union)** - мера точности локализации полей:
   - IoU = Площадь пересечения / Площадь объединения
   - Значения от 0 до 1, где 1 означает идеальное совпадение

2. **Character Accuracy** - мера точности распознавания текста:
   - Character Accuracy = Количество правильно распознанных символов / Общее количество символов
   - Значения от 0 до 1, где 1 означает идеальное распознавание

Пример вывода метрик:
```
==================================================
ОБРАБОТКА ФАЙЛА: passport1.jpg
==================================================

Метрики для текущего изображения:
  surname:
    IoU: 0.9234
    Character Accuracy: 0.8571
  name:
    IoU: 0.9156
    Character Accuracy: 0.9000
  // ... другие поля

==================================================
СРЕДНИЕ МЕТРИКИ ПО ВСЕМУ ДАТАСЕТУ:
==================================================
  surname:
    IoU: 0.9123
    Character Accuracy: 0.8456
  name:
    IoU: 0.9234
    Character Accuracy: 0.9123
  // ... другие поля
==================================================
```
